---------------------------------------------------------------------------
Training stage 0
Sampled 1237 windows from 614 images.
Done sampling windows (time=14s).
Extracting features... done (time=12s).
Computing correlations... done (time=4s).
Extracting features... done (time=23s).
Computing lambdas... done (time=76s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=2s).
Extracting features... done (time=5s).
Training AdaBoost: nWeak= 32 nFtrs=20480 pos=22266 neg=5000
 i=  16 alpha=1.000 err=0.225 loss=2.07e-02
 i=  32 alpha=1.000 err=0.241 loss=1.04e-03
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=5.0s).
Done training stage 0 (time=146s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 448 images.
Done sampling windows (time=15s).
Extracting features... done (time=5s).
Training AdaBoost: nWeak=128 nFtrs=20480 pos=22266 neg=10000
 i=  16 alpha=1.000 err=0.309 loss=1.38e-01
 i=  32 alpha=1.000 err=0.304 loss=3.19e-02
 i=  48 alpha=1.000 err=0.307 loss=7.47e-03
 i=  64 alpha=1.000 err=0.314 loss=1.91e-03
 i=  80 alpha=1.000 err=0.306 loss=5.03e-04
 i=  96 alpha=1.000 err=0.297 loss=1.27e-04
 i= 112 alpha=1.000 err=0.315 loss=3.24e-05
 i= 128 alpha=1.000 err=0.319 loss=8.58e-06
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=10.9s).
Done training stage 1 (time=32s).
---------------------------------------------------------------------------
Training stage 2
Sampled 2160 windows from 1218 images.
Done sampling windows (time=36s).
Extracting features... done (time=2s).
Training AdaBoost: nWeak=512 nFtrs=20480 pos=22266 neg=10000
 i=  16 alpha=1.000 err=0.329 loss=2.19e-01
 i=  32 alpha=1.000 err=0.323 loss=7.84e-02
 i=  48 alpha=1.000 err=0.339 loss=2.97e-02
 i=  64 alpha=1.000 err=0.345 loss=1.12e-02
 i=  80 alpha=1.000 err=0.342 loss=4.33e-03
 i=  96 alpha=1.000 err=0.333 loss=1.74e-03
 i= 112 alpha=1.000 err=0.332 loss=6.51e-04
 i= 128 alpha=1.000 err=0.332 loss=2.58e-04
 i= 144 alpha=1.000 err=0.350 loss=9.81e-05
 i= 160 alpha=1.000 err=0.338 loss=3.70e-05
 i= 176 alpha=1.000 err=0.328 loss=1.30e-05
 i= 192 alpha=1.000 err=0.340 loss=4.83e-06
 i= 208 alpha=1.000 err=0.342 loss=1.93e-06
 i= 224 alpha=1.000 err=0.338 loss=7.32e-07
 i= 240 alpha=1.000 err=0.342 loss=2.71e-07
 i= 256 alpha=1.000 err=0.336 loss=9.94e-08
 i= 272 alpha=1.000 err=0.334 loss=3.64e-08
 i= 288 alpha=1.000 err=0.340 loss=1.31e-08
 i= 304 alpha=1.000 err=0.335 loss=4.95e-09
 i= 320 alpha=1.000 err=0.335 loss=1.80e-09
 i= 336 alpha=1.000 err=0.341 loss=6.81e-10
 i= 352 alpha=1.000 err=0.341 loss=2.55e-10
 i= 368 alpha=1.000 err=0.342 loss=9.24e-11
 i= 384 alpha=1.000 err=0.342 loss=3.46e-11
 i= 400 alpha=1.000 err=0.334 loss=1.30e-11
 i= 416 alpha=1.000 err=0.345 loss=4.72e-12
 i= 432 alpha=1.000 err=0.323 loss=1.80e-12
 i= 448 alpha=1.000 err=0.331 loss=6.99e-13
 i= 464 alpha=1.000 err=0.341 loss=2.63e-13
 i= 480 alpha=1.000 err=0.333 loss=9.54e-14
 i= 496 alpha=1.000 err=0.342 loss=3.63e-14
 i= 512 alpha=1.000 err=0.329 loss=1.29e-14
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=32.3s).
Done training stage 2 (time=71s).
---------------------------------------------------------------------------
Training stage 3
Sampled 187 windows from 1218 images.
Done sampling windows (time=37s).
Extracting features... done (time=0s).
Training AdaBoost: nWeak=2048 nFtrs=20480 pos=22266 neg=10000
 i=  16 alpha=1.000 err=0.348 loss=2.34e-01
 i=  32 alpha=1.000 err=0.339 loss=9.19e-02
 i=  48 alpha=1.000 err=0.346 loss=3.60e-02
 i=  64 alpha=1.000 err=0.335 loss=1.38e-02
 i=  80 alpha=1.000 err=0.338 loss=5.57e-03
 i=  96 alpha=1.000 err=0.354 loss=2.24e-03
 i= 112 alpha=1.000 err=0.344 loss=9.03e-04
 i= 128 alpha=1.000 err=0.335 loss=3.48e-04
 i= 144 alpha=1.000 err=0.346 loss=1.41e-04
 i= 160 alpha=1.000 err=0.347 loss=5.46e-05
 i= 176 alpha=1.000 err=0.340 loss=2.29e-05
 i= 192 alpha=1.000 err=0.339 loss=9.37e-06
 i= 208 alpha=1.000 err=0.345 loss=3.77e-06
 i= 224 alpha=1.000 err=0.342 loss=1.44e-06
 i= 240 alpha=1.000 err=0.349 loss=5.61e-07
 i= 256 alpha=1.000 err=0.339 loss=2.25e-07
 i= 272 alpha=1.000 err=0.328 loss=8.75e-08
 i= 288 alpha=1.000 err=0.342 loss=3.48e-08
 i= 304 alpha=1.000 err=0.346 loss=1.36e-08
 i= 320 alpha=1.000 err=0.330 loss=5.36e-09
 i= 336 alpha=1.000 err=0.336 loss=2.11e-09
 i= 352 alpha=1.000 err=0.338 loss=8.23e-10
 i= 368 alpha=1.000 err=0.335 loss=3.31e-10
 i= 384 alpha=1.000 err=0.344 loss=1.33e-10
 i= 400 alpha=1.000 err=0.347 loss=5.41e-11
 i= 416 alpha=1.000 err=0.342 loss=2.19e-11
 i= 432 alpha=1.000 err=0.349 loss=8.57e-12
 i= 448 alpha=1.000 err=0.333 loss=3.36e-12
 i= 464 alpha=1.000 err=0.355 loss=1.36e-12
 i= 480 alpha=1.000 err=0.343 loss=5.38e-13
 i= 496 alpha=1.000 err=0.333 loss=2.18e-13
 i= 512 alpha=1.000 err=0.343 loss=8.70e-14
 i= 528 alpha=1.000 err=0.337 loss=3.55e-14
 i= 544 alpha=1.000 err=0.341 loss=1.42e-14
 i= 560 alpha=1.000 err=0.339 loss=5.64e-15
 i= 576 alpha=1.000 err=0.349 loss=2.29e-15
 i= 592 alpha=1.000 err=0.333 loss=8.81e-16
 i= 608 alpha=1.000 err=0.345 loss=3.39e-16
 i= 624 alpha=1.000 err=0.340 loss=1.33e-16
 i= 640 alpha=1.000 err=0.341 loss=5.06e-17
 i= 656 alpha=1.000 err=0.349 loss=1.95e-17
 i= 672 alpha=1.000 err=0.347 loss=7.62e-18
 i= 688 alpha=1.000 err=0.347 loss=2.90e-18
 i= 704 alpha=1.000 err=0.342 loss=1.14e-18
 i= 720 alpha=1.000 err=0.353 loss=4.53e-19
 i= 736 alpha=1.000 err=0.347 loss=1.79e-19
 i= 752 alpha=1.000 err=0.340 loss=6.92e-20
 i= 768 alpha=1.000 err=0.336 loss=2.62e-20
 i= 784 alpha=1.000 err=0.342 loss=9.99e-21
 i= 800 alpha=1.000 err=0.349 loss=3.93e-21
 i= 816 alpha=1.000 err=0.355 loss=1.60e-21
 i= 832 alpha=1.000 err=0.339 loss=6.26e-22
 i= 848 alpha=1.000 err=0.355 loss=2.41e-22
 i= 864 alpha=1.000 err=0.335 loss=9.61e-23
 i= 880 alpha=1.000 err=0.349 loss=3.91e-23
 i= 896 alpha=1.000 err=0.348 loss=1.57e-23
 i= 912 alpha=1.000 err=0.341 loss=6.09e-24
 i= 928 alpha=1.000 err=0.340 loss=2.49e-24
 i= 944 alpha=1.000 err=0.344 loss=9.94e-25
 i= 960 alpha=1.000 err=0.338 loss=3.87e-25
 i= 976 alpha=1.000 err=0.340 loss=1.57e-25
 i= 992 alpha=1.000 err=0.334 loss=6.04e-26
 i=1008 alpha=1.000 err=0.342 loss=2.38e-26
 i=1024 alpha=1.000 err=0.344 loss=9.46e-27
 i=1040 alpha=1.000 err=0.341 loss=3.71e-27
 i=1056 alpha=1.000 err=0.348 loss=1.52e-27
 i=1072 alpha=1.000 err=0.340 loss=6.04e-28
 i=1088 alpha=1.000 err=0.333 loss=2.38e-28
 i=1104 alpha=1.000 err=0.341 loss=9.32e-29
 i=1120 alpha=1.000 err=0.338 loss=3.57e-29
 i=1136 alpha=1.000 err=0.345 loss=1.33e-29
 i=1152 alpha=1.000 err=0.349 loss=5.10e-30
 i=1168 alpha=1.000 err=0.348 loss=2.03e-30
 i=1184 alpha=1.000 err=0.345 loss=7.63e-31
 i=1200 alpha=1.000 err=0.339 loss=2.93e-31
 i=1216 alpha=1.000 err=0.342 loss=1.13e-31
 i=1232 alpha=1.000 err=0.327 loss=4.40e-32
 i=1248 alpha=1.000 err=0.348 loss=1.75e-32
 i=1264 alpha=1.000 err=0.353 loss=6.82e-33
 i=1280 alpha=1.000 err=0.340 loss=2.68e-33
 i=1296 alpha=1.000 err=0.349 loss=1.06e-33
 i=1312 alpha=1.000 err=0.338 loss=4.18e-34
 i=1328 alpha=1.000 err=0.341 loss=1.64e-34
 i=1344 alpha=1.000 err=0.347 loss=6.69e-35
 i=1360 alpha=1.000 err=0.354 loss=2.66e-35
 i=1376 alpha=1.000 err=0.329 loss=1.06e-35
 i=1392 alpha=1.000 err=0.344 loss=4.23e-36
 i=1408 alpha=1.000 err=0.339 loss=1.71e-36
 i=1424 alpha=1.000 err=0.355 loss=6.51e-37
 i=1440 alpha=1.000 err=0.336 loss=2.47e-37
 i=1456 alpha=1.000 err=0.327 loss=9.69e-38
 i=1472 alpha=1.000 err=0.338 loss=3.76e-38
 i=1488 alpha=1.000 err=0.337 loss=1.50e-38
 i=1504 alpha=1.000 err=0.354 loss=6.10e-39
 i=1520 alpha=1.000 err=0.344 loss=2.36e-39
 i=1536 alpha=1.000 err=0.348 loss=9.09e-40
 i=1552 alpha=1.000 err=0.336 loss=3.55e-40
 i=1568 alpha=1.000 err=0.340 loss=1.41e-40
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=87.8s).
Done training stage 3 (time=126s).
---------------------------------------------------------------------------
Done training (time=376s).
